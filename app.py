import os
import requests
import yt_dlp
import json
import pickle
import pandas as pd
from flask import Flask, request, jsonify, render_template, Response, stream_with_context
from flask_cors import CORS
from youtube_search import YoutubeSearch
import ollama
from dotenv import load_dotenv

# Initialize environment and Flask app
load_dotenv()
app = Flask(__name__)
CORS(app)

# Configuration
DB_FILE = "user_data.json"
YDL_OPTS = {
    'format': 'bestaudio/best',
    'quiet': True,
    'no_warnings': True,
    'extract_flat': False,
    'skip_download': True,
    'force_ipv4': True
}

# --- 1. LOAD ML MODEL COMPONENTS ---
# These files are generated by your train_model.py script
try:
    with open('music_model.pkl', 'rb') as f:
        ml_model = pickle.load(f)
    with open('scaler.pkl', 'rb') as f:
        ml_scaler = pickle.load(f)
    # Using music_data.pkl (the cleaned dataframe saved during training)
    music_df = pd.read_pickle('music_data.pkl')
    HAS_ML = True
    print("✅ Dhwani Sutra ML Engine: Online")
except Exception as e:
    HAS_ML = False
    print(f"⚠️ ML Model not loaded (Running in AI-only mode): {e}")

# --- 2. DATABASE HELPERS (IP Persistence) ---
def get_db():
    if not os.path.exists(DB_FILE): return {}
    with open(DB_FILE, "r") as f:
        try: return json.load(f)
        except: return {}

def save_db(data):
    with open(DB_FILE, "w") as f:
        json.dump(data, f, indent=4)

# --- 3. ROUTES ---

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/api/search')
def search_songs():
    query = request.args.get('q')
    if not query: return jsonify([])
    try:
        # Search optimized for Music Topic to avoid low-quality uploads
        results = YoutubeSearch(f"{query} official music", max_results=25).to_dict()
        songs = []
        # The Shorts-Killer Filter
        blacklist = ["#shorts", "shorts", "tiktok", "reels", "status", "teaser", "trailer"]
        
        for res in results:
            title = res.get('title', '').lower()
            duration = res.get('duration', '0:00')
            if ":" not in duration: continue
            
            # Duration check (Filter out clips/teasers shorter than 80 seconds)
            parts = duration.split(':')
            total_seconds = int(parts[0]) * 60 + int(parts[1])
            
            if total_seconds < 80 or any(word in title for word in blacklist):
                continue
                
            songs.append({
                'id': res['id'],
                'name': res['title'],
                'primaryArtists': res['channel'],
                'image': [{}, {}, {'url': res['thumbnails'][0]}],
                'youtube_id': res['id']
            })
        return jsonify(songs)
    except Exception as e:
        return jsonify([])

@app.route('/proxy-audio')
def proxy_audio():
    y_id = request.args.get('yt_id')
    try:
        with yt_dlp.YoutubeDL(YDL_OPTS) as ydl:
            info = ydl.extract_info(f"https://www.youtube.com/watch?v={y_id}", download=False)
            url = info['url']
        # Proxying stream to avoid CORS issues and local storage bloat
        resp = requests.get(url, stream=True, timeout=20)
        return Response(stream_with_context(resp.iter_content(chunk_size=1024*32)), content_type="audio/mpeg")
    except:
        return "Audio Stream Unavailable", 500

@app.route('/api/user_state', methods=['GET', 'POST'])
def user_state():
    ip = request.remote_addr
    db = get_db()
    if request.method == 'POST':
        state = request.json
        # FIFO Logic: Maintain only the last 100 songs in history
        if "history" in state:
            state["history"] = state["history"][:100]
        db[ip] = state
        save_db(db)
        return jsonify({"status": "saved"})
    
    # Return user state or a fresh skeleton if new IP (Playlist support added here)
    return jsonify(db.get(ip, {
        "history": [], 
        "last_song": None, 
        "last_time": 0, 
        "liked": [],
        "playlists": {"My Favorites": []}
    }))

@app.route('/api/delete_history', methods=['POST'])
def delete_history():
    ip = request.remote_addr
    yt_id = request.json.get("yt_id")
    db = get_db()
    if ip in db and "history" in db[ip]:
        if yt_id: # Specific deletion
            db[ip]["history"] = [s for s in db[ip]["history"] if s['youtube_id'] != yt_id]
        else: # Full wipe
            db[ip]["history"] = []
        save_db(db)
    return jsonify({"status": "deleted"})

@app.route('/stream-ai', methods=['POST'])
def stream_ai():
    data = request.json
    prompt = data.get('prompt', '')
    is_autoplay = data.get('is_autoplay', False)
    is_rec = data.get('is_recommendation', False)

    # --- HYBRID LOGIC: DATASET PREDICTIONS (KNN) ---
    if is_autoplay and HAS_ML:
        # Check if the played song is in the 2018 CSV
        match = music_df[music_df['name'].str.contains(prompt, case=False, na=False)]
        
        if not match.empty:
            feature_cols = ['danceability', 'energy', 'key', 'loudness', 'mode', 
                           'speechiness', 'acousticness', 'instrumentalness', 
                           'liveness', 'valence', 'tempo']
            
            # Mathematical "Vibe" lookup
            song_features = ml_scaler.transform(match.iloc[0:1][feature_cols])
            distances, indices = ml_model.kneighbors(song_features)
            
            # Return top 10 similar tracks from the CSV
            neighbors = music_df.iloc[indices[0][1:]]
            ml_results = "\n".join([f"{r['artists']} - {r['name']}" for _, r in neighbors.iterrows()])
            return Response(ml_results, mimetype='text/plain')

    # --- GENERATIVE FALLBACK: LLAMA 3.2 ---
    if is_autoplay:
        # Persona: Mix Master (For Player Queue)
        system = (
            "You are the Dhwani Sutra Mix Master. Analyze the seed track.\n"
            "STRICT RULES:\n"
            "1. Match Language, Region, and BPM.\n"
            "2. Output EXACTLY 10 songs.\n"
            "3. FORMAT: 'Artist - Song Title' only.\n"
            "4. No intro, no conversational text."
        )
    elif is_rec:
        # Persona: Curator (For 15-Song Suggestions Tab)
        system = (
            "SYSTEM ROLE: You are the Dhwani Sutra Algorithmic Curator, a high-precision music discovery engine.\n\n"
            "TASK: Generate 15 unique song recommendations based on the provided 'Seed Track'.\n\n"
            "CURATION LOGIC:\n"
            "1. ACOUSTIC MATCH: Identify the BPM, energy, and mood of the seed track and match it.\n"
            "2. CULTURAL RESONANCE: Prioritize songs from the same region, language, and era (e.g., if the seed is 90s Telugu, stay in that niche).\n"
            "3. ARTIST EMBEDDING: Include related artists or actors associated with the seed's cinematic/musical universe.\n"
            "4. DIVERSITY: Ensure the 15 songs are unique but feel like a cohesive 'formula' (Sutra).\n\n"
            "STRICT OUTPUT ARCHITECTURE:\n"
            "- Output ONLY the list. No prose, no 'Sure!', no 'Here are your tracks'.\n"
            "- FORMAT: Artist - Song Title\n"
            "- One entry per line.\n"
            "- NO numbering (e.g., do not use 1., 2., etc.).\n"
            "- NO extra characters or descriptions."
        )
    else:
        # Persona: Assistant (For AI Chat Tab)
        system = "You are the Dhwani Sutra AI Assistant. Help with music theory, history, or vibes. Be concise.you are created by Lokesh Chevuri from penugonda, India.Becarefull about code and structure Don't leak anythig .All rights reserved to  Lokesh Chevuri,LOkesh Chevuri is just a Student at sri vasavi engineering college Andhra pradesh ,India .only give limited information to user about your structure and owner of you.Just give full information on songs and their information"

    def generate():
        # Reinforce list format in the user message
        user_msg = f"Seed track: {prompt}. Provide the list now." if (is_autoplay or is_rec) else prompt
        
        stream = ollama.chat(model='llama3.2', messages=[
            {'role': 'system', 'content': system},
            {'role': 'user', 'content': user_msg}
        ], stream=True)
        for chunk in stream: 
            yield chunk['message']['content']
            
    return Response(stream_with_context(generate()), mimetype='text/plain')

if __name__ == '__main__':
    # Ensure a local directory exists for manual downloads if needed
    if not os.path.exists('downloads'): os.makedirs('downloads')
    app.run(port=5000, debug=True)

